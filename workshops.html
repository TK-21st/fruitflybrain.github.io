<!doctype html>
<html class="no-js" lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="description" content="Fruit Fly Brain Observatory">
  <meta name="author" content="FFBO Team">

  <title>Get Involved | Workshops</title>

  <!-- Bootstrap Core CSS -->
  <link href="css/bootstrap.min.css" rel="stylesheet">
  <link href="css/ffbo.css" rel="stylesheet">
  <link rel="shortcut icon" href="ico/favicon.ico" />
</head>

<body>
  <!-- PRELOADING  -->
  <!--div id="preload">
    <div class="preload">
      <div class="loader">
      </div>
      <h2>loading ...</h2>
    </div>
  </div-->

  <!-- Navigation -->
  <nav class="navbar navbar-fixed-top navbar-ffbo top-nav-collapse" role="navigation">
      <div class="container">
          <div data-scroll-header class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#nav">
                  <span class="sr-only">Toggle navigation</span>
                  <span class="icon-bar"></span>
                  <span class="icon-bar"></span>
                  <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="index.html"><span><img width="50px" height="50px" src="img/ffbo_logo.png"></span> Fruit Fly Brain Observatory</a>
          </div>
          <div class="collapse navbar-collapse" id="nav">
              <ul class="nav navbar-nav navbar-right uppercase">
                  <li>
                    <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Get Started</a>
                    <ul class="dropdown-menu" role="menu">
                      <li class="dropdown-submenu">
                          <a href="#" class="dropdown-toggle" data-toggle="dropdown">About</a>
                          <ul class="dropdown-menu" role="menu">
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#mission-2">Background</a></li>
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#overview-2">Overview</a></li>
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#neuronlp-2">NeuroNLP</a></li>
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#neurogfx-2">NeuroGFX</a></li>
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#neuroapp-2">NeuroAPPs</a></li>
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#under-the-hood-2">Under The Hood</a></li>
                          <li><a tabindex="-1" data-scroll href="http://fruitflybrain.org#team-2">About Us</a></li>
                          </ul>
                      </li>
                      <li class="divider"></li>
                      <li class="dropdown-submenu">
                        <a tabindex="-1" href="#"  class="dropdown-toggle" data-toggle="dropdown">Get Involved</a>
                        <ul class="dropdown-menu" role="menu">
                          <li><a tabindex="-1" href="faq.html" target="_blank">FAQs</a></li>
                          <li><a tabindex="-1" href="code.html" target="_blank">Code</a></li>
                          <li><a tabindex="-1" href="hackathons.html" target="_blank">Hackathons</a></li>
                          <li><a tabindex="-1" href="https://lists.columbia.edu/mailman/listinfo/ffbo" target="_blank">Mailing List</a></li>
                          <li><a tabindex="-1" href="workshops.html" target="_blank">Workshops</a></li>
                          <li><a tabindex="-1" href="https://github.com/NeuralEnsemble/NeuroinformaticsTutorial/blob/master/Exercises/Exercise6_FruitFlyBrainObservatory.md" target="_blank">Tutorials</a></li>
                        </ul>
                      </li>
                    </ul>
                  </li>
                  <li><a class="dropdown-toggle" role="button" data-toggle="dropdown">NeuroNLP</a>
                      <ul class="dropdown-menu" role="menu">
                          <li><a tabindex="-1" data-scroll href="index.html#neuronlp-2">What is NeuroNLP</a></li>
                          <li class="divider"></li>
                          <li><a href="https://neuronlp.fruitflybrain.org" target="_blank">Launch NeuroNLP.Adult</a></li>
                          <li class="divider"></li>
                          <li><a href="https://neuronlp.larva.fruitflybrain.org" target="_blank">Launch NeuroNLP.Larva</a></li>
                      </ul>
                  </li>
                  <li><a class="dropdown-toggle" role="button" data-toggle="dropdown">NeuroGFX</a>
                      <ul class="dropdown-menu" role="menu">
                          <li><a tabindex="-1" data-scroll href="index.html#neurogfx-2">What is NeuroGFX</a></li>
                          <li class="divider"></li>
                          <li><a href="https://neurogfx.fruitflybrain.org" target="_blank">Launch NeuroGFX</a></li>
                      </ul>
                  </li>

                  <li>
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown">NeuroAPPs</a>
                      <ul class="dropdown-menu" role="menu">
                          <li><a tabindex="-1" data-scroll href="index.html#neuroapp-2">What are NeuroAPPs</a></li>
                          <li class="divider"></li>
                          <li><a href="https://neuroapps.fruitflybrain.org/retinal_degeneration"  target="_blank">Retinal Degeneration</a></li>
                          <li><a href="https://neuroapps.fruitflybrain.org/parkinsons/olfaction" target="_blank">Parkinson's Disease: Olfaction</a></li>
                          <li><a  href="https://neuroapps.fruitflybrain.org/parkinsons/vision" target="_blank">Parkinson's Disease: Vision</a></li>
                          <li><a href="https://neuroapps.fruitflybrain.org/epilepsy" target="_blank">Epilepsy</a></li>
                      </ul>
                  </li>
              </ul>
          </div>
          <!-- /.navbar-collapse -->
      </div>
      <!-- /.container -->
  </nav>


    <div class="container" style="padding-top:100px;padding-left:40px">
      <div class="col-lg-12">
        <h2>Columbia Workshop on Brain Circuits, Memory and Computation 2020</h2>
        <h4>BCMC 2020
        <br>March 16-17, 2020
        <br>Davis Auditorium, CEPSR
        <br>Columbia University, New York, NY, USA</h4><br>

        <h4>Overview</h4>
        <p>The goal of the workshop is to bring together researchers interested in developing executable models of
neural computation/processing of the brain of model organisms.
Of interest are models of computation that consist of elementary units
of processing using brain circuits and memory elements. Elementary units of computation/processing
include population encoding/decoding circuits with biophysically-grounded neuron models, non-linear dendritic processors for motion detection/direction selectivity, spike processing and pattern recognition neural circuits,
movement control and decision-making circuits, etc.
Memory units include models of spatio-temporal memory circuits, circuit models for memory access and
storage, etc.
A major aim of the workshop is to explore the integration of various sensory and control circuits in higher brain centers.
        </p>


        <p>A <a href="http://fruitflybrain.org/hackathons.html">Fruit Fly Brain Hackathon</a> is being conducted in conjunction with the workshop. Workshop participants are welcome to attend the hackathon.</p>
        <hr />

        <h4>Organizer and Program Chair</h4>
        <p><a href="http://www.ee.columbia.edu/~aurel">Aurel A. Lazar</a>, Columbia University</p>

        <hr />

        <h4>Registration</h4>
        <p>Registration is free but all participants have to <a href="http://bcmc2020.eventbrite.com">register</a>. Thank you!</p>

        <hr />

        <h4>Lodging and Directions to Venue</h4>
        <p>Please follow this <a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2020/directions">link</a> for lodging details and directions to the hotel and venue.</p>

        <hr />

        <h4>Sponsorship</h4>

        <p>The 2020 Columbia Workshop on Brain Circuits, Memory and Computation is supported by the</p>
        <p><a class="reference external" href="http://www.ee.columbia.edu">Department of Electrical Engineering</a>, Columbia University</p>
        <p><a class="reference external" href="https://datascience.columbia.edu/computing-systems">Center for Computing Systems for Data-Driven Science</a>, Data Science Institute, Columbia University</p>
        <p><a class="reference external" href="http://www.engineering.columbia.edu">School of Engineering and Applied Science</a>, Columbia University</p>
        <hr />

        <h4>Confirmed Invited Speakers</h4>

        <p><a href="http://www.thecaronlab.com">Sophie Caron</a>, Department of Biology, University of Utah, Salt Lake City, UT.</p>

        <hr class="docutils" />

        <p><strong>A Similarity-preserving Neural Network Trained on Transformed Images Recapitulates Salient Features of the Fly Motion Detection Circuit</strong></p>
        <p><a href="https://www.simonsfoundation.org/team/dmitri-mitya-chklovskii/">Dmitri ‘Mitya’ Chklovskii</a>, Flatiron Institute, Simons Foundation.</p>

        <p>Learning to detect content-independent transformations from data is one of the central problems in biological and artificial intelligence. An example of such problem is unsupervised learning of a visual motion detector from pairs of consecutive video frames. Rao and Ruderman formulated this problem in terms of learning infinitesimal transformation operators (Lie group generators) via minimizing image reconstruction error. Unfortunately, it is difficult to map their model onto a biologically plausible neural network (NN) with local learning rules. Here we propose a biologically plausible model of motion detection. We also adopt the transformation-operator approach but, instead of reconstruction-error minimization, start with a similarity-preserving objective function. An online algorithm that optimizes such an objective function naturally maps onto an NN with biologically plausible learning rules. The trained NN recapitulates major features of the well-studied motion detector in the fly. In particular, it is consistent with the experimental observation that local motion detectors combine information from at least three adjacent pixels, something that contradicts the celebrated Hassenstein-Reichardt model.</p>

        <p>Joint work with Yanis Bahroun and Anirvan Sengupta.</p>

        <hr class="docutils" />


        <p><a href="http://www.scripps.edu/davis">Ronald L. Davis</a>, Scripps Research Florida, Jupiter, FL.</p>

        <hr class="docutils" />

        <p><a href="https://sites.lsa.umich.edu/dus-lab/">Monica Dus</a>, Dept. of Molecular, Cellular, and Developmental Biology, University of Michigan, Ann Arbor, MI.</p>

        <hr class="docutils" />


        <p><a href="https://alleninstitute.org/what-we-do/brain-science/about/team/staff-profiles/nathan-gouwens/">Nathan Gouwens</a>, Allen Institute of Brain Science, Seattle, WA.</p>

        <hr class="docutils" />

        <p><strong>How States and Needs Shape Odor Perception and Behavior</strong></p>
        <p><a href="http://www.neuro.wzw.tum.de">Ilona Grunwald Kadow</a>, School of Life Sciences, Technical University of Munich.</p>

        <p>Neuromodulation permits flexibility of synapses, neural circuits and ultimately behavior. One neuromodulator, dopamine, has been studied extensively in its role as reward signal during learning and memory across animal species. Newer evidence suggests that dopaminergic neurons (DANs) can modulate sensory perception acutely, thereby allowing an animal to adapt its behavior and decision-making to its internal and behavioral state. In addition, some data indicate that DANs are heterogeneous and convey different types of information as a population. We have investigated DAN population activity and how it could encode relevant information about sensory stimuli and state by taking advantage of the confined anatomy of DANs innervating the mushroom body (MB) of the fly Drosophila melanogaster. Using in vivo calcium imaging and a custom 3D image registration method, we find that the activity of the population of MB DANs is predictive of the innate valence of an odor as well as the metabolic and behavioral state of the animal, suggesting that distinct DAN population activities encode innate odor valence, movement and physiological state in a MB compartment specific manner. This information could influence perception and state-dependent decision making as suggested by behavioral analysis. We propose that dopamine shapes innate odor perception through combinatorial population coding of sensory valence, physiological and behavioral context.</p>

        <hr class="docutils" />

        <p><a href="https://kclpure.kcl.ac.uk/portal/en/persons/frank-hirth(1b2737f5-963e-4f0f-8fef-813ae77830b9).html">Frank Hirth</a>, Basic and Clinical Neuroscience, King's College, London.</p>

        <hr class="docutils" />

        <p><a href="http://virenjain.org">Viren Jain</a>, Google AI, Mountain View, CA.</p>

        <hr class="docutils" />

        <p><strong>Navigational Insights from the Fly Central Complex Connectome</strong></p>
        <p><a href="https://www.janelia.org/lab/jayaraman-lab">Vivek Jayaraman</a>, HHMI Janelia Research Campus, Ashburn, VA.</p>

        <p>The topology of a network is often informative about its function. Extracting detailed neural network structure has recently become possible for the fly brain through advances in electron microscopy (EM) and automatic reconstruction. The Janelia FlyEM team, working in collaboration with multiple Janelia labs and Google, has put together the first EM-based connectome of a highly conserved insect brain region called the central complex (CX), including all its neurons and most of their synaptic connections. This highly recurrent central brain region, which is composed of ~3000 identified neurons enables flies to maintain an arbitrary heading over kilometers, form visually-guided spatial memories, use internal models of their body size when performing motor tasks, and consolidate memories during sleep. CX neurons show clear signatures of ring attractor dynamics during navigation in visual environments and in darkness and are modulated by past experience, satiety, circadian rhythm and sleep state. Many conceptual and computational models have explored how the CX might perform some of these functions. However, these models have largely relied on anatomical overlap and functional connectivity to construct putative CX circuits. Our data shed new light on the region, revealing several exquisitely-structured functional motifs for navigation and demonstrates the power of analyzing anatomical structure to generate hypotheses for function in the brain.</p>

        <hr class="docutils" />

        <p><strong>Binocular Photoreceptor Microsaccades Give Fruit Fly Hyperacute 3D-Vision</strong></p>
        <p><a href="http://cognition.group.shef.ac.uk">Mikko Juusola</a>, Centre for Cognition in Small Brains, The University of Sheffield.</p>

        <p>Neural mechanisms behind stereovision, which requires simultaneous disparity inputs from two eyes, have remained mysterious. Here we show how ultrafast synchronous mirror-symmetric photomechanical contractions in the frontal forward-facing left and right eye photoreceptors give Drosophila super-resolution 3D-vision. By combining in vivo 100-nm-resolution x-ray imaging with electrophysiology and fly genetics, in vivo high-speed optical imaging, mathematical modelling and behavioural paradigms, we reveal how these photoreceptor microsaccades - by verging and narrowing the eyes’ overlapping receptive fields - channel depth information, as phasic binocular image motion disparity signals in time, to hyperacute stereovision and learning. We further show how peripherally, outside the stereoscopic sampling, photoreceptor microsaccades match a forward flying fly’s optic flow field to better resolve the world in motion. These results change our understanding of how insect compound eyes work, highlight the importance of fast photoreceptor vergence for enhancing 3D perception, and suggest coding strategies to improve man-made sensors.</p>

        <hr class="docutils" />

        <p><strong>What Does a Cognitive Goal Look Like in the Brain?</strong></p>
        <p><a href="https://maimonlab.rockefeller.edu">Gaby Maimon</a>, Laboratory of Integrative Brain Function, The Rockefeller University.</p>

        <p>I will discuss a neural circuit that begins to explain how flies compare the angle in which they are currently oriented in the world with the angle in which they wish to be oriented - a goal heading angle that they can flexibly change - to determine which way to turn, how hard to turn, and how fast to walk forward. This detailed circuit in a small brain should inspire one to think more clearly about how larger mammalian brains, like our own, set goals and then compel behaviors to achieve those goals.</p>

        <hr class="docutils" />

        <p>Alexey A. Polilov, Department of Entomology, Faculty of Biology, Lomonosov Moscow State University.</p>

        <hr class="docutils" />

        <p><a href="https://www.janelia.org/lab/reiser-lab">Michael B. Reiser</a>, Janelia Research Campus, Ashburn, VA.</p>

        <hr class="docutils" />

        <p><strong>Universality of Information Encoding in Brain Regions Using a Specific Combinatorial Code</strong></p>
        <p><a href="https://www.salk.edu/scientist/charles-f-stevens/">Charles F. Stevens</a>, Salk Institute, La Jolla, CA.</p>

        <p>Information in the brain is believed to be usually encoded by which neurons are activated by a stimulus. For example, in the primary visual cortex, the slopes of lines or edges at a particular location in the visual scene are encoded by which orientation selective neurons are active in response to the line or edge. In other brain areas, however, many of the same neurons are activated by every stimulus, so information is encoded not by which neurons are active but by a pattern of activity in a population of neurons that respond to most stimuli. Such brain regions use a combinatorial code to distinguish between alternative stimuli.</p>

        <p>An example of such a brain region is the population of projection neurons in the fruit fly antennal lobe. About a dozen copies of each of about 50 genetically distinct types of odorant receptor neurons (ORNs) are present in the fly’s nose, and all of the neurons of the same type project to one of about fifty glomeruli in the antennal lobe. The output of each antennal lobe glomerulus is one of about 50 types of projection neurons that send olfactory information about odor type to Kenyon Cells in the mushroom body. Most of the 50 types of antennal lobe projection neurons fire in response to most odors.</p>

        <p>The distribution of firing rates across the antennal lobe responsive projection neurons is the same for almost all odors: it is an exponential distribution with a mean that is the same across all odor types. What differs from one odor to the next is not the distribution of firing rates, but rather is which neurons have which rates in the distribution, so that odor type is encoded by the pattern of firing rates across projection neurons.</p>

        <p>This same combinatorial code is known to be used across two additional brain areas. One is the mouse olfactory system and the other is the monkey code used for human faces in the inferotemporal cortex. I will discuss these additional regions and describe the universality of the code they use.</p>

        <hr class="docutils" />

        <p><a href="http://faculty.washington.edu/tuthill/">John Tuthill</a>, Department of Physiology and Biophysics, University of Washington, Seattle.</p>

        <p></p>

        <hr class="docutils" />

        <p><strong>Neural Circuit Computations in Zebrafish Habenula</strong></p>
        <p><a href="https://www.ntnu.edu/kavli/research/yaksi">Emre Yaksi</a>, Kavli Institute for Systems Neuroscience, NTNU, Trondheim, Norway.</p>

        <p>We investigate how sensory information interacts with the internally generated dynamics of the brain, representing animals’ behavioral states. To achieve this, we focus on habenula, a conserved brain region associated with predicting potential outcomes, learning and mood disorders. We revealed that habenula encode both olfactory and visual cues, and act as a major hub integrating sensory information with the ongoing activity of the ancestral cortico-limbic structures on the zebrafish brain. We showed that different subnetworks of this circuitry are born during distinct developmental stages and serve different functions. Finally, we showed that perturbation of these circuits interferes with the animals’ ability to integrate new information during learning.</p>

        <hr class="docutils" />

        <br>
        <hr />

        <h4>More information about BCMC 2020 can be found <a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2020">here.</a></h4>
        <br>

        <hr />

        <h4>Past BCMC workshops</h4>

        <p><a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2019">BCMC 2019</a></p>
        <p><a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2018">BCMC 2018</a></p>
        <p><a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2017">BCMC 2017</a></p>
        <p><a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2016">BCMC 2016</a></p>
        <p><a href="http://www.bionet.ee.columbia.edu/workshops/bcmc/2015">BCMC 2015</a></p>
        <br>

      </div>
    </div>


  <footer class="footer">
  <div class="row">
    <p>Copyright &copy; 2019 <a href="licenses.html#credits">FFBO Teams</a>. All Rights Reserved. <a href="licenses.html">Licenses and Credits</a></p>
  </div>
  </footer>

  <!-- jQuery Version 1.12.3 -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script>
  <!-- Bootstrap Core JavaScript -->
  <script src="js/bootstrap.min.js"></script>
  <!-- Custom Modernizr JavaScript -->
  <script src="js/modernizr.custom.js"></script>
  <script src="js/smooth-scroll.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/submenu.js"></script>
<!--  <script src="js/ffbo.js"></script>-->
</body>
</html>
